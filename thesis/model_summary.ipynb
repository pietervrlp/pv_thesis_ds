{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, GRU, Dense, Flatten, Conv1D, Dropout\n",
    "from tensorflow.keras.layers import LeakyReLU, ReLU, TimeDistributed\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "from utils import process_dataframe, split_train_test, scaler_function, get_X_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = 'ASTE'\n",
    "dataframe = pd.read_feather('./data/XGBoost10/df_%s_XGBoost10.feather' % (stock))\n",
    "\n",
    "df = process_dataframe(dataframe)\n",
    "\n",
    "X_value = pd.DataFrame(df.iloc[:, :])\n",
    "y_value = pd.DataFrame(df.iloc[:, 0]) #first column is the closing price\n",
    "\n",
    "X_train, X_test = split_train_test(X_value, train_dimension=0.8)\n",
    "y_train, y_test = split_train_test(y_value.values, train_dimension=0.8)\n",
    "\n",
    "X_scaler, y_scaler = scaler_function(X_train, y_train)\n",
    "    \n",
    "X_train = X_scaler.fit_transform(X_train)\n",
    "y_train = y_scaler.fit_transform(y_train)\n",
    "X_test = X_scaler.fit_transform(X_test)\n",
    "y_test = y_scaler.fit_transform(y_test)\n",
    "\n",
    "n_steps_in = 2\n",
    "n_steps_out = 1\n",
    "X_train, y_train, past_y_train = get_X_y(X_train, y_train, n_steps_in, n_steps_out)\n",
    "output_dim = y_train.shape[1]\n",
    "weight_initializer = RandomNormal(mean=0.00, stddev=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_3 (Conv1D)           (None, 2, 32)             1248      \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 2, 32)             0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 128)              37632     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " leaky_re_lu_9 (LeakyReLU)   (None, 32)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,249\n",
      "Trainable params: 49,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def Generator(input_dim, output_dim, feature_size, weight_initializer) -> tf.keras.models.Model:    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Conv1D(32, kernel_size=2, strides=1, \n",
    "                     padding='same',kernel_initializer= weight_initializer, \n",
    "                     batch_input_shape=(None,input_dim,feature_size)))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Bidirectional(GRU(64, activation='relu', kernel_initializer= weight_initializer, return_sequences=False, \n",
    "                                 dropout=0.2, recurrent_dropout=0.0)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(64, activation='linear'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dense(32, activation='linear'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    \n",
    "    model.add(Dense(output_dim))\n",
    "    return model\n",
    "\n",
    "generator = Generator(X_train.shape[1], output_dim, X_train.shape[2], weight_initializer)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_4 (Conv1D)           (None, 3, 32)             96        \n",
      "                                                                 \n",
      " leaky_re_lu_10 (LeakyReLU)  (None, 3, 32)             0         \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 3, 64)             4160      \n",
      "                                                                 \n",
      " leaky_re_lu_11 (LeakyReLU)  (None, 3, 64)             0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 192)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                12352     \n",
      "                                                                 \n",
      " leaky_re_lu_12 (LeakyReLU)  (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " leaky_re_lu_13 (LeakyReLU)  (None, 32)                0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,721\n",
      "Trainable params: 18,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def Discriminator(weight_initializer, n_steps_in, n_steps_out) -> tf.keras.models.Model:\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Conv1D(32, kernel_size=2, strides=1,\n",
    "                     kernel_initializer= weight_initializer, padding='same', \n",
    "                     input_shape=(n_steps_in + n_steps_out, 1)))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Conv1D(64, kernel_size=2, strides=1,\n",
    "                     kernel_initializer= weight_initializer, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(64, activation='linear', use_bias=True))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='linear', use_bias=True))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    return model\n",
    "\n",
    "discriminator = Discriminator(weight_initializer, n_steps_in, n_steps_out)\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m2tex(model):\n",
    "    stringlist = []\n",
    "    model.summary(line_length=90, print_fn=lambda x: stringlist.append(x))\n",
    "    del stringlist[1:-4:2]\n",
    "    del stringlist[-1]\n",
    "    for ix in range(1,len(stringlist)-3):\n",
    "        tmp = stringlist[ix]\n",
    "        stringlist[ix] = tmp[0:39]+\"&\"+tmp[39:75]+\"&\"+tmp[75:]+\"\\\\\\\\ \\hline\"\n",
    "    stringlist[0] = \"Model: test \\\\\\\\ \\hline\"\n",
    "    stringlist[1] = stringlist[1]+\" \\hline\"\n",
    "    stringlist[-4] = stringlist[-4]+\" \\hline\"\n",
    "    stringlist[-3] = stringlist[-3]+\" \\\\\\\\\"\n",
    "    stringlist[-2] = stringlist[-2]+\" \\\\\\\\\"\n",
    "    stringlist[-1] = stringlist[-1]+\" \\\\\\\\ \\hline\"\n",
    "    prefix = [\"\\\\begin{table}[]\", \"\\\\begin{tabular}{lll}\"]\n",
    "    suffix = [\"\\end{tabular}\", \"\\caption{Model summary for test.}\", \"\\label{tab:model-summary}\" , \"\\end{table}\"]\n",
    "    stringlist = prefix + stringlist + suffix \n",
    "    out_str = \" \\n\".join(stringlist)\n",
    "    out_str = out_str.replace(\"_\", \"\\_\")\n",
    "    out_str = out_str.replace(\"#\", \"\\#\")\n",
    "    print(out_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[] \n",
      "\\begin{tabular}{lll} \n",
      "Model: test \\\\ \\hline \n",
      " Layer (type)                          & Output Shape                       & Param \\#       \\\\ \\hline \\hline \n",
      " conv1d\\_3 (Conv1D)                     & (None, 2, 32)                      & 1248          \\\\ \\hline \n",
      " leaky\\_re\\_lu\\_7 (LeakyReLU)             & (None, 2, 32)                      & 0             \\\\ \\hline \n",
      " bidirectional\\_1 (Bidirectional)       & (None, 128)                        & 37632         \\\\ \\hline \n",
      " dropout\\_2 (Dropout)                   & (None, 128)                        & 0             \\\\ \\hline \n",
      " flatten\\_2 (Flatten)                   & (None, 128)                        & 0             \\\\ \\hline \n",
      " dense\\_6 (Dense)                       & (None, 64)                         & 8256          \\\\ \\hline \n",
      " leaky\\_re\\_lu\\_8 (LeakyReLU)             & (None, 64)                         & 0             \\\\ \\hline \n",
      " dense\\_7 (Dense)                       & (None, 32)                         & 2080          \\\\ \\hline \n",
      " leaky\\_re\\_lu\\_9 (LeakyReLU)             & (None, 32)                         & 0             \\\\ \\hline \n",
      " dense\\_8 (Dense)                       & (None, 1)                          & 33            \\\\ \\hline \n",
      "=======================================&====================================&===============\\\\ \\hline \\hline \n",
      "Total params: 49,249 \\\\ \n",
      "Trainable params: 49,249 \\\\ \n",
      "Non-trainable params: 0 \\\\ \\hline \n",
      "\\end{tabular} \n",
      "\\caption{Model summary for test.} \n",
      "\\label{tab:model-summary} \n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "m2tex(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[] \n",
      "\\begin{tabular}{lll} \n",
      "Model: test \\\\ \\hline \n",
      " Layer (type)                          & Output Shape                       & Param \\#       \\\\ \\hline \\hline \n",
      " conv1d\\_4 (Conv1D)                     & (None, 3, 32)                      & 96            \\\\ \\hline \n",
      " leaky\\_re\\_lu\\_10 (LeakyReLU)            & (None, 3, 32)                      & 0             \\\\ \\hline \n",
      " conv1d\\_5 (Conv1D)                     & (None, 3, 64)                      & 4160          \\\\ \\hline \n",
      " leaky\\_re\\_lu\\_11 (LeakyReLU)            & (None, 3, 64)                      & 0             \\\\ \\hline \n",
      " flatten\\_3 (Flatten)                   & (None, 192)                        & 0             \\\\ \\hline \n",
      " dense\\_9 (Dense)                       & (None, 64)                         & 12352         \\\\ \\hline \n",
      " leaky\\_re\\_lu\\_12 (LeakyReLU)            & (None, 64)                         & 0             \\\\ \\hline \n",
      " dropout\\_3 (Dropout)                   & (None, 64)                         & 0             \\\\ \\hline \n",
      " dense\\_10 (Dense)                      & (None, 32)                         & 2080          \\\\ \\hline \n",
      " leaky\\_re\\_lu\\_13 (LeakyReLU)            & (None, 32)                         & 0             \\\\ \\hline \n",
      " dropout\\_4 (Dropout)                   & (None, 32)                         & 0             \\\\ \\hline \n",
      " dense\\_11 (Dense)                      & (None, 1)                          & 33            \\\\ \\hline \n",
      "=======================================&====================================&===============\\\\ \\hline \\hline \n",
      "Total params: 18,721 \\\\ \n",
      "Trainable params: 18,721 \\\\ \n",
      "Non-trainable params: 0 \\\\ \\hline \n",
      "\\end{tabular} \n",
      "\\caption{Model summary for test.} \n",
      "\\label{tab:model-summary} \n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "m2tex(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "53c8288164b111909136d47c9fb6e53b341cebfa55ed6a6b1547ffbd05c57601"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
